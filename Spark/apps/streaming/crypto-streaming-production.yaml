apiVersion: spark.apache.org/v1
kind: SparkApplication
metadata:
  name: crypto-streaming-10m
  namespace: crypto-infra
  labels:
    app: crypto-streaming
    env: production
    version: v1.0.0
  annotations:
    description: "Aggregates 1-minute crypto klines to 10-minute intervals"
spec:
  mainApplicationFile: "local:///opt/spark/work-dir/spark_streaming_10m.py"
  
  sparkConf:
    spark.jars.packages: "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0"
    
    spark.dynamicAllocation.enabled: "true"
    spark.dynamicAllocation.shuffleTracking.enabled: "true"
    spark.dynamicAllocation.minExecutors: "2"
    spark.dynamicAllocation.maxExecutors: "10"
    spark.dynamicAllocation.initialExecutors: "3"
    spark.dynamicAllocation.executorIdleTimeout: "60s"
    spark.dynamicAllocation.cachedExecutorIdleTimeout: "300s"
    
    spark.kubernetes.authenticate.driver.serviceAccountName: "spark"
    spark.kubernetes.container.image: "apache/spark:3.5.0"
    spark.kubernetes.allocation.batch.size: "5"
    
    spark.driver.cores: "2"
    spark.driver.memory: "4g"
    spark.driver.memoryOverhead: "1g"
    
    spark.executor.cores: "2"
    spark.executor.memory: "4g"
    spark.executor.memoryOverhead: "1g"
    
    spark.eventLog.enabled: "true"
    spark.eventLog.dir: "file:///tmp/spark-events"
    spark.eventLog.compress: "true"
    
    spark.streaming.stopGracefullyOnShutdown: "true"
    spark.streaming.backpressure.enabled: "true"
    spark.sql.streaming.schemaInference: "true"
    spark.sql.streaming.checkpointLocation: "file:///tmp/spark-checkpoint"
    
    spark.sql.adaptive.enabled: "true"
    spark.sql.adaptive.coalescePartitions.enabled: "true"
    spark.sql.adaptive.skewJoin.enabled: "true"
    spark.sql.shuffle.partitions: "200"
    spark.default.parallelism: "100"
    
    spark.memory.fraction: "0.8"
    spark.memory.storageFraction: "0.3"
    
    spark.network.timeout: "300s"
    spark.executor.heartbeatInterval: "20s"
    
    spark.speculation: "true"
    spark.speculation.interval: "100ms"
    spark.speculation.multiplier: "1.5"
    spark.speculation.quantile: "0.75"
    
    spark.metrics.conf.*.sink.prometheusServlet.class: "org.apache.spark.metrics.sink.PrometheusServlet"
    spark.metrics.conf.*.sink.prometheusServlet.path: "/metrics"
    spark.metrics.conf.*.source.jvm.class: "org.apache.spark.metrics.source.JvmSource"
    
    spark.kubernetes.driverEnv.KAFKA_BOOTSTRAP_SERVERS: "my-cluster-kafka-bootstrap.crypto-infra.svc.cluster.local:9092"
    spark.kubernetes.driverEnv.KAFKA_TOPIC: "crypto_kline_1m"
    spark.kubernetes.driverEnv.SPARK_LOG_LEVEL: "INFO"
    spark.executorEnv.KAFKA_BOOTSTRAP_SERVERS: "my-cluster-kafka-bootstrap.crypto-infra.svc.cluster.local:9092"
    
    spark.kubernetes.driver.label.app: "crypto-streaming"
    spark.kubernetes.driver.label.component: "driver"
    spark.kubernetes.driver.label.version: "3.5.0"
    
    spark.kubernetes.executor.label.app: "crypto-streaming"
    spark.kubernetes.executor.label.component: "executor"
    spark.kubernetes.executor.label.version: "3.5.0"
    
    spark.kubernetes.driver.annotation.prometheus.io/scrape: "true"
    spark.kubernetes.driver.annotation.prometheus.io/port: "4040"
    spark.kubernetes.driver.annotation.prometheus.io/path: "/metrics/prometheus"
  
  applicationTolerations:
    resourceRetainPolicy: OnFailure
    restartConfig:
      restartPolicy: OnFailure
      maxRestartAttempts: 5
      restartBackoffMillis: 30000
    instanceConfig:
      initExecutors: 3
      minExecutors: 2
      maxExecutors: 10
  
  runtimeVersions:
    scalaVersion: "2.12"
    sparkVersion: "3.5.0"
