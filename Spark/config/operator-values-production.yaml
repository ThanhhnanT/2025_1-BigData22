image:
  repository: apache/spark-kubernetes-operator
  pullPolicy: IfNotPresent
  tag: 0.6.0

operatorDeployment:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  
  operatorPod:
    operatorContainer:
      jvmArgs: "-Dfile.encoding=UTF8 -XX:+ExitOnOutOfMemoryError -XX:+UseParallelGC -XX:InitialRAMPercentage=80 -XX:MaxRAMPercentage=80 -Dio.netty.noUnsafe=true"
      
      resources:
        limits:
          cpu: "2"
          ephemeral-storage: 4Gi
          memory: 4Gi
        requests:
          cpu: "1"
          ephemeral-storage: 2Gi
          memory: 2Gi
      
      probes:
        port: 19091
        livenessProbe:
          periodSeconds: 10
          initialDelaySeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          periodSeconds: 10
          initialDelaySeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        startupProbe:
          failureThreshold: 30
          periodSeconds: 10
      
      metrics:
        port: 19090
      
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
            - ALL
        runAsNonRoot: true
        runAsUser: 185
        seccompProfile:
          type: RuntimeDefault
    
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - spark-kubernetes-operator
            topologyKey: kubernetes.io/hostname
    
    topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: topology.kubernetes.io/zone
      whenUnsatisfiable: ScheduleAnyway
      labelSelector:
        matchLabels:
          app.kubernetes.io/name: spark-kubernetes-operator

operatorRbac:
  serviceAccount:
    create: true
    name: "spark-operator"
  clusterRole:
    create: true
    name: "spark-operator-clusterrole"
  clusterRoleBinding:
    create: true
    name: "spark-operator-clusterrolebinding"
  configManagement:
    create: true
    roleName: "spark-operator-config-monitor"
    roleBindingName: "spark-operator-config-monitor-role-binding"

workloadResources:
  namespaces:
    create: false
    overrideWatchedNamespaces: true
    data:
      - "crypto-infra"
  
  serviceAccount:
    create: true
    name: "spark"
  
  clusterRole:
    create: true
    name: "spark-workload-clusterrole"
  
  roleBinding:
    create: true
    name: "spark-workload-rolebinding"
  
  annotations:
    "helm.sh/resource-policy": keep
  
  labels:
    "app.kubernetes.io/component": "spark-workload"

operatorConfiguration:
  append: true
  log4j2.properties: |+
    rootLogger.level=INFO
    rootLogger.appenderRef.stdout.ref = console
    appender.console.type = Console
    appender.console.name = console
    appender.console.target = SYSTEM_ERR
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %X{resource.name} %X{resource.namespace} %C{1.} %m%n%ex
    
    logger.spark.name = org.apache.spark
    logger.spark.level = WARN
    logger.k8s.name = io.fabric8.kubernetes
    logger.k8s.level = WARN
  
  spark-operator.properties: |+
    spark.kubernetes.operator.reconciler.intervalSeconds=30
    spark.kubernetes.operator.reconciler.batchSize=10
    spark.kubernetes.operator.reconciler.fullReconciliation.enabled=true
    spark.kubernetes.operator.reconciler.fullReconciliation.intervalSeconds=300
  
  metrics.properties: |+
    *.sink.prometheus.class=org.apache.spark.metrics.sink.PrometheusServlet
    *.sink.prometheus.path=/metrics
    *.source.jvm.class=org.apache.spark.metrics.source.JvmSource
  
  dynamicConfig:
    enable: true
    create: true
    annotations:
      "helm.sh/resource-policy": keep
    data:
      spark.kubernetes.operator.reconciler.intervalSeconds: "30"
      spark.kubernetes.operator.reconciler.batchSize: "10"

