image:
  repository: apache/spark-kubernetes-operator
  pullPolicy: IfNotPresent
  tag: 0.6.0

operatorDeployment:
  replicas: 1
  strategy:
    type: Recreate
  
  operatorPod:
    operatorContainer:
      resources:
        limits:
          cpu: "500m"
          ephemeral-storage: 1Gi
          memory: 1Gi
        requests:
          cpu: "250m"
          ephemeral-storage: 512Mi
          memory: 512Mi
      
      probes:
        port: 19091
        livenessProbe:
          periodSeconds: 10
          initialDelaySeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          periodSeconds: 10
          initialDelaySeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        startupProbe:
          failureThreshold: 30
          periodSeconds: 10
      
      metrics:
        port: 19090
      
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
            - ALL
        runAsNonRoot: true
        runAsUser: 185
        seccompProfile:
          type: RuntimeDefault

operatorRbac:
  serviceAccount:
    create: true
    name: "spark-operator"
  clusterRole:
    create: true
    name: "spark-operator-clusterrole"
  clusterRoleBinding:
    create: true
    name: "spark-operator-clusterrolebinding"
  configManagement:
    create: true
    roleName: "spark-operator-config-monitor"
    roleBindingName: "spark-operator-config-monitor-role-binding"

workloadResources:
  namespaces:
    create: false
    overrideWatchedNamespaces: true
    data:
      - "crypto-infra"
  
  serviceAccount:
    create: true
    name: "spark"
  
  clusterRole:
    create: true
    name: "spark-workload-clusterrole"
  
  roleBinding:
    create: true
    name: "spark-workload-rolebinding"
  
  annotations:
    "helm.sh/resource-policy": keep
  
  labels:
    "app.kubernetes.io/component": "spark-workload"

operatorConfiguration:
  append: true
  log4j2.properties: |+
    rootLogger.level=INFO
    rootLogger.appenderRef.stdout.ref = console
    appender.console.type = Console
    appender.console.name = console
    appender.console.target = SYSTEM_ERR
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %X{resource.name} %X{resource.namespace} %C{1.} %m%n%ex
  
  spark-operator.properties: |+
    spark.kubernetes.operator.reconciler.intervalSeconds=10
  
  dynamicConfig:
    enable: true
    create: true
    annotations:
      "helm.sh/resource-policy": keep
    data:
      spark.kubernetes.operator.reconciler.intervalSeconds: "10"

