# H·ªá Th·ªëng X·ª≠ L√Ω D·ªØ Li·ªáu Cryptocurrency - Real-time Trading Platform

## üë• Th√†nh Vi√™n Nh√≥m

| H·ªç v√† T√™n | MSSV |
|-----------|------|
| V∆∞∆°ng VƒÉn Th√†nh | 20225094 |
| Ph·∫°m Huy S∆°n | 20225080 |
| Tr·∫ßn Tu·∫•n H√πng | 20225000 |
| V≈© Anh Huy | 20220029 |
| Tr·∫ßn Tu·∫•n H·∫£i | 20224976 |

---

## üìñ Gi·ªõi Thi·ªáu

H·ªá th·ªëng x·ª≠ l√Ω d·ªØ li·ªáu cryptocurrency to√†n di·ªán v·ªõi kh·∫£ nƒÉng x·ª≠ l√Ω real-time v√† batch processing, t√≠ch h·ª£p Machine Learning ƒë·ªÉ d·ª± ƒëo√°n gi√° v√† ph√¢n t√≠ch th·ªã tr∆∞·ªùng. D·ª± √°n ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n n·ªÅn t·∫£ng Kubernetes v·ªõi c√°c c√¥ng ngh·ªá Big Data hi·ªán ƒë·∫°i nh∆∞ Apache Kafka, Apache Spark, v√† Apache Airflow.

## üéØ M·ª•c Ti√™u D·ª± √Ån

D·ª± √°n n√†y l√† m·ªôt h·ªá th·ªëng end-to-end ƒë·ªÉ thu th·∫≠p, x·ª≠ l√Ω, l∆∞u tr·ªØ v√† hi·ªÉn th·ªã d·ªØ li·ªáu cryptocurrency t·ª´ Binance Exchange. H·ªá th·ªëng h·ªó tr·ª£:

- **Real-time Data Streaming**: Thu th·∫≠p d·ªØ li·ªáu kline, orderbook, v√† trades t·ª´ Binance WebSocket API
- **Batch Processing**: X·ª≠ l√Ω v√† t·ªïng h·ª£p d·ªØ li·ªáu OHLC theo nhi·ªÅu khung th·ªùi gian (5m, 1h, 4h, 1d)
- **Machine Learning**: D·ª± ƒëo√°n gi√° cryptocurrency s·ª≠ d·ª•ng Spark ML Linear Regression
- **Real-time Dashboard**: Giao di·ªán web hi·ªÉn th·ªã bi·ªÉu ƒë·ªì trading, orderbook, v√† ranking
- **Monitoring & Observability**: Gi√°m s√°t h·ªá th·ªëng v·ªõi Prometheus v√† Grafana

## üèóÔ∏è Ki·∫øn Tr√∫c H·ªá Th·ªëng

### Workflow T·ªïng Quan

![Workflow](images/WorkFlow.png)

### C√°c Th√†nh Ph·∫ßn Ch√≠nh

#### 1. **Data Ingestion Layer**
- **Kafka Producers**: Thu th·∫≠p d·ªØ li·ªáu real-time t·ª´ Binance WebSocket API
  - Kline data (1m interval) cho 15+ cryptocurrency pairs
  - Orderbook updates v·ªõi depth 20 levels
  - Market trades real-time
- **Kafka Topics**: 
  - `crypto_kline_1m`: D·ªØ li·ªáu kline 1 ph√∫t
  - `crypto_orderbook`: D·ªØ li·ªáu orderbook
  - `crypto_trades`: D·ªØ li·ªáu giao d·ªãch

#### 2. **Data Processing Layer**
- **Apache Spark**: 
  - **Batch Processing**: T·ªïng h·ª£p OHLC data (5m, 1h, 4h, 1d) t·ª´ d·ªØ li·ªáu 1m
  - **Streaming Processing**: X·ª≠ l√Ω real-time ƒë·ªÉ t√≠nh to√°n ranking v√† metrics
  - **ML Pipeline**: Training v√† prediction model cho gi√° cryptocurrency
- **Apache Airflow**: Orchestration v√† scheduling cho c√°c Spark jobs
  - Scheduled DAGs cho batch aggregation
  - ML model training pipeline
  - Data cleanup v√† maintenance tasks

#### 3. **Data Storage Layer**
- **MongoDB**: L∆∞u tr·ªØ d·ªØ li·ªáu l·ªãch s·ª≠ OHLC ƒë√£ ƒë∆∞·ª£c t·ªïng h·ª£p
  - Collections: `5m_kline`, `1h_kline`, `4h_kline`, `1d_kline`, `predictions`
- **Redis**: Cache d·ªØ li·ªáu real-time cho frontend
  - Latest kline data
  - Orderbook snapshots
  - Market trades
  - Ranking data (top gainers/losers)
  - ML predictions

#### 4. **API & Backend Layer**
- **FastAPI**: RESTful API v√† WebSocket server
  - REST endpoints cho historical data t·ª´ MongoDB
  - WebSocket streams cho real-time updates t·ª´ Redis
  - ML prediction endpoints
  - Coin ranking endpoints

#### 5. **Frontend Layer**
- **Next.js**: Trading dashboard v·ªõi c√°c t√≠nh nƒÉng:
  - Real-time candlestick charts v·ªõi TradingView integration
  - Orderbook visualization v·ªõi depth chart
  - Market trades feed v·ªõi color coding
  - Coin ranking table (top gainers/losers)
  - ML predictions display v·ªõi confidence scores

#### 6. **Monitoring Layer**
- **Prometheus**: Metrics collection v√† storage
  - Kafka producer/consumer metrics
  - Spark job execution metrics
  - API latency metrics
  - System resource metrics
- **Grafana**: Visualization v√† alerting
  - System health dashboards
  - Application performance monitoring
  - Data pipeline health checks

### System Dashboard

![Grafana Dashboard](images/Grafana.png)

## üìÅ C·∫•u Tr√∫c Th∆∞ M·ª•c

```
CRYPTO/
‚îú‚îÄ‚îÄ airflow/                    # Apache Airflow orchestration
‚îÇ   ‚îú‚îÄ‚îÄ dags/                   # DAG definitions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ohlc_spark_aggregator.py    # OHLC aggregation DAGs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml_prediction_dag.py        # ML training DAG
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ redis_clear_and_history_fetch_dag.py
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ backend_fastapi/            # FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py             # API endpoints & WebSocket handlers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Configuration settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py          # Pydantic models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ kafka_manager.py    # Shared Kafka consumer manager
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ frontend/                   # Next.js frontend
‚îÇ   ‚îú‚îÄ‚îÄ app/                    # Next.js app directory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx            # Main dashboard page
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orderbook/          # Orderbook page
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ charts/             # Trading charts components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TradingDashboard.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ChartEmbedded.tsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                 # UI components
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îú‚îÄ‚îÄ Kafka/                      # Kafka producers
‚îÇ   ‚îú‚îÄ‚îÄ binance_producer.py     # Kline data producer
‚îÇ   ‚îú‚îÄ‚îÄ binance_orderbook_trades_producer.py
‚îÇ   ‚îú‚îÄ‚îÄ redis_consumer.py       # Consumer to Redis
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ Spark/                      # Apache Spark jobs
‚îÇ   ‚îú‚îÄ‚îÄ batch/                  # Batch processing scripts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ohlc_5m_aggregator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ohlc_1h_aggregator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ohlc_4h_aggregator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ohlc_1d_aggregator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_price_prediction.py
‚îÇ   ‚îú‚îÄ‚îÄ ranking_coins/          # Ranking calculation
‚îÇ   ‚îú‚îÄ‚îÄ apps/                   # SparkApplication YAMLs for K8s
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ
‚îú‚îÄ‚îÄ mongodb/                    # MongoDB Helm chart
‚îú‚îÄ‚îÄ redis/                      # Redis Helm chart
‚îú‚îÄ‚îÄ Prometheus/                 # Prometheus Helm chart
‚îÇ
‚îú‚îÄ‚îÄ deploy/                     # Deployment configurations
‚îÇ   ‚îú‚îÄ‚îÄ k8s_web/                # Kubernetes manifests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ frontend-deployment.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backend-deployment.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ namespace.yaml
‚îÇ   ‚îî‚îÄ‚îÄ helm/                   # Helm deployment scripts
‚îÇ
‚îî‚îÄ‚îÄ images/                     # Documentation images
    ‚îú‚îÄ‚îÄ WorkFlow.png
    ‚îú‚îÄ‚îÄ Chart.png
    ‚îú‚îÄ‚îÄ rank.png
    ‚îú‚îÄ‚îÄ Grafana.png
    ‚îî‚îÄ‚îÄ SysTemDashBoard.png
```

## üöÄ T√≠nh NƒÉng Ch√≠nh

### 1. Real-time Data Streaming

H·ªá th·ªëng thu th·∫≠p d·ªØ li·ªáu real-time t·ª´ Binance WebSocket API:
- **Kline Data**: D·ªØ li·ªáu n·∫øn 1 ph√∫t cho 15+ cryptocurrency pairs (BTC, ETH, BNB, SOL, ADA, XRP, DOGE, DOT, MATIC, AVAX, LINK, UNI, LTC, ATOM, ETC)
- **Orderbook**: Order book depth v·ªõi updates real-time (20 levels bids/asks)
- **Market Trades**: L·ªãch s·ª≠ giao d·ªãch real-time v·ªõi th√¥ng tin price, quantity, v√† buyer/seller

### 2. Batch Processing & Aggregation

Spark batch jobs t·ªïng h·ª£p d·ªØ li·ªáu t·ª´ 1m interval th√†nh c√°c khung th·ªùi gian l·ªõn h∆°n:
- **5 ph√∫t (5m)**: Cho ph√¢n t√≠ch ng·∫Øn h·∫°n
- **1 gi·ªù (1h)**: Cho ph√¢n t√≠ch trung b√¨nh
- **4 gi·ªù (4h)**: Cho ph√¢n t√≠ch d√†i h·∫°n
- **1 ng√†y (1d)**: Cho ph√¢n t√≠ch xu h∆∞·ªõng

M·ªói aggregation job ƒë∆∞·ª£c schedule t·ª± ƒë·ªông b·ªüi Airflow.

### 3. Machine Learning Predictions

![Chart](images/Chart.png)

H·ªá th·ªëng ML s·ª≠ d·ª•ng Spark ML Linear Regression ƒë·ªÉ d·ª± ƒëo√°n:
- **Gi√° cryptocurrency** trong 5 ph√∫t ti·∫øp theo
- **H∆∞·ªõng bi·∫øn ƒë·ªông** (tƒÉng/gi·∫£m) v·ªõi confidence score
- **Technical indicators** ƒë∆∞·ª£c t√≠nh to√°n t·ª± ƒë·ªông (RSI, MACD, Moving Averages)

Model ƒë∆∞·ª£c training ƒë·ªãnh k·ª≥ v·ªõi d·ªØ li·ªáu l·ªãch s·ª≠ 30 ng√†y.

### 4. Coin Ranking System

![Ranking](images/rank.png)

T√≠nh to√°n v√† hi·ªÉn th·ªã ranking c√°c coin real-time:
- **Top Gainers**: Coin tƒÉng gi√° nhi·ªÅu nh·∫•t (percent change)
- **Top Losers**: Coin gi·∫£m gi√° nhi·ªÅu nh·∫•t
- **Metrics**: Percent change, volume, market cap, price change

Ranking ƒë∆∞·ª£c c·∫≠p nh·∫≠t real-time th√¥ng qua Spark streaming job.

### 5. Real-time Trading Dashboard

Giao di·ªán web v·ªõi c√°c t√≠nh nƒÉng:
- **Interactive candlestick charts**: TradingView charting library v·ªõi zoom, pan, v√† technical indicators
- **Real-time orderbook visualization**: Depth chart v·ªõi color coding
- **Market trades feed**: Real-time trades v·ªõi buy/sell indicators
- **Coin ranking table**: Sortable table v·ªõi pagination
- **ML predictions display**: Hi·ªÉn th·ªã predictions v·ªõi confidence scores v√† direction indicators

## üõ†Ô∏è C√¥ng Ngh·ªá S·ª≠ D·ª•ng

### Data Processing
- **Apache Kafka**: Message streaming platform cho real-time data ingestion
- **Apache Spark**: Distributed data processing
  - Spark SQL cho data transformation
  - Spark MLlib cho machine learning
  - Spark Structured Streaming cho real-time processing
- **Apache Airflow**: Workflow orchestration v√† scheduling

### Storage
- **MongoDB**: Document database cho historical OHLC data
- **Redis**: In-memory cache cho real-time data v√† session management

### Backend
- **FastAPI**: High-performance Python web framework
- **WebSocket**: Real-time bidirectional communication
- **Pydantic**: Data validation v√† serialization
- **Motor**: Async MongoDB driver
- **Redis Async**: Async Redis client

### Frontend
- **Next.js 14**: React framework v·ªõi App Router v√† SSR
- **TypeScript**: Type-safe JavaScript
- **TradingView Charting Library**: Professional charting
- **Tailwind CSS**: Utility-first CSS framework
- **shadcn/ui**: Component library

### Infrastructure
- **Kubernetes**: Container orchestration
- **Docker**: Containerization
- **Helm**: Kubernetes package manager
- **Prometheus**: Metrics monitoring v√† alerting
- **Grafana**: Visualization v√† dashboards
- **Strimzi**: Kafka operator cho Kubernetes

## üì¶ C√†i ƒê·∫∑t & Tri·ªÉn Khai

### Prerequisites

- **Kubernetes cluster** (Minikube, Kind, ho·∫∑c cloud K8s nh∆∞ GKE, EKS, AKS)
- **kubectl** configured v√† c√≥ quy·ªÅn truy c·∫≠p cluster
- **Helm 3.x** installed
- **Docker** (cho local development)
- **Python 3.9+** (cho local development)

## üöÄ Tri·ªÉn Khai L√™n AWS EKS

### Prerequisites cho AWS EKS

- **AWS CLI** installed v√† configured v·ªõi credentials
- **Terraform >= 1.5.0** installed
- **kubectl** installed
- **Helm 3.x** installed
- **Docker** installed (cho building images)
- AWS Account v·ªõi quy·ªÅn t·∫°o EKS, VPC, IAM resources

### 1. Deploy Infrastructure v·ªõi Terraform

```bash
# Navigate to terraform directory
cd terraform

# Copy v√† ch·ªânh s·ª≠a terraform.tfvars
cp terraform.tfvars.example terraform.tfvars
# Edit terraform.tfvars v·ªõi c√°c gi√° tr·ªã ph√π h·ª£p

# Initialize Terraform
terraform init

# Plan deployment
terraform plan

# Apply infrastructure
terraform apply

# L∆∞u √Ω: Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t 15-20 ph√∫t ƒë·ªÉ t·∫°o EKS cluster
```

Sau khi Terraform ho√†n th√†nh, b·∫°n s·∫Ω c√≥:
- VPC v·ªõi public v√† private subnets
- EKS cluster v·ªõi managed node groups
- ECR repositories cho Docker images
- IAM roles v√† policies
- EKS add-ons (ALB Controller, EBS CSI Driver, etc.)

### 2. Setup Kubeconfig

```bash
# S·ª≠ d·ª•ng script t·ª± ƒë·ªông
cd scripts
./setup-kubeconfig.sh [CLUSTER_NAME] [REGION]

# Ho·∫∑c manual
aws eks update-kubeconfig --region ap-southeast-1 --name crypto-eks

# Verify connection
kubectl cluster-info
kubectl get nodes
```

### 3. Build v√† Push Docker Images l√™n ECR

```bash
# S·ª≠ d·ª•ng script t·ª± ƒë·ªông
cd scripts
./build-and-push-images.sh [REGION] [CLUSTER_NAME]

# Script s·∫Ω:
# - Login v√†o ECR
# - Build t·∫•t c·∫£ Docker images
# - Tag v√† push l√™n ECR repositories
```

Sau khi push images, l·∫•y ECR URLs t·ª´ Terraform output:
```bash
cd terraform
terraform output ecr_repository_urls
```

### 4. Update Kubernetes Manifests v·ªõi ECR URLs

C·∫≠p nh·∫≠t c√°c file deployment v·ªõi ECR image URLs:

**backend-deployment.yaml**:
```yaml
image: <AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com/crypto-eks/crypto-backend-fastapi:latest
```

**frontend-deployment.yaml**:
```yaml
image: <AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com/crypto-eks/crypto-frontend-next:latest
```

**Kafka producer deployments**:
```yaml
image: <AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com/crypto-eks/crypto-binance-producer:latest
```

### 5. Update ConfigMap cho AWS Environment

```bash
cd deploy/k8s_web

# S·ª≠ d·ª•ng AWS-specific configmap
cp configmap-aws.yaml.example configmap-aws.yaml
# Ch·ªânh s·ª≠a v·ªõi service names ph√π h·ª£p

kubectl apply -f configmap-aws.yaml
```

### 6. Deploy Infrastructure Components (MongoDB, Redis, Kafka)

```bash
# Deploy MongoDB
cd mongodb
helm install mongodb . -n crypto-infra --create-namespace

# Deploy Redis
cd redis
helm install redis . -n crypto-infra

# Deploy Kafka (Strimzi Operator)
cd Kafka/strimzi-kafka-operator
kubectl apply -f install/cluster-operator/
kubectl wait --for=condition=ready pod -l name=strimzi-cluster-operator -n strimzi-system --timeout=300s
kubectl apply -f kafka-helm.yaml

# Deploy Prometheus & Grafana
cd deploy/helm
./deploy-monitoring.sh
```

### 7. Deploy Application Components

```bash
cd deploy/k8s_web

# T·∫°o namespace
kubectl apply -f namespace.yaml

# Deploy ConfigMap v√† Secrets
kubectl apply -f configmap-aws.yaml
kubectl apply -f secret.yaml

# Deploy Backend API
kubectl apply -f backend-deployment.yaml
kubectl apply -f backend-service.yaml

# Deploy Frontend
kubectl apply -f frontend-deployment.yaml
kubectl apply -f frontend-service.yaml

# Deploy Ingress (s·ª≠ d·ª•ng ALB)
kubectl apply -f ingress.yaml
```

### 8. L·∫•y ALB URL

Sau khi Ingress ƒë∆∞·ª£c t·∫°o, ALB s·∫Ω ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông. L·∫•y URL:

```bash
# ƒê·ª£i ALB ƒë∆∞·ª£c t·∫°o (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)
kubectl get ingress -n crypto-app

# Ho·∫∑c l·∫•y t·ª´ AWS CLI
aws elbv2 describe-load-balancers --query 'LoadBalancers[?contains(LoadBalancerName, `crypto`)].DNSName' --output text
```

### 9. Verify Deployment

```bash
# Check pods
kubectl get pods -n crypto-app
kubectl get pods -n crypto-infra

# Check services
kubectl get svc -n crypto-app
kubectl get svc -n crypto-infra

# Check ingress
kubectl get ingress -n crypto-app

# View logs
kubectl logs -f deployment/backend-fastapi -n crypto-app
kubectl logs -f deployment/frontend-next -n crypto-app
```

### 10. Cleanup (Khi c·∫ßn x√≥a infrastructure)

```bash
cd terraform

# Destroy all resources
terraform destroy

# L∆∞u √Ω: ƒêi·ªÅu n√†y s·∫Ω x√≥a to√†n b·ªô infrastructure bao g·ªìm:
# - EKS cluster v√† node groups
# - VPC v√† networking
# - ECR repositories (images s·∫Ω b·ªã x√≥a)
# - IAM roles v√† policies
```

### AWS EKS Configuration Notes

- **Node Groups**: H·ªá th·ªëng s·ª≠ d·ª•ng 3 node groups:
  - `application`: Cho frontend/backend (t3.large)
  - `data-processing`: Cho Spark/Kafka workloads (t3.xlarge)
  - `system`: Cho monitoring/infrastructure (t3.medium)

- **Networking**: 
  - Worker nodes ch·∫°y trong private subnets
  - ALB trong public subnets
  - VPC endpoints cho S3/ECR ƒë·ªÉ gi·∫£m NAT costs

- **Storage**: 
  - EBS CSI Driver ƒë∆∞·ª£c c√†i ƒë·∫∑t t·ª± ƒë·ªông
  - Storage classes s·∫µn c√≥ cho persistent volumes

- **Security**:
  - IAM roles v·ªõi least privilege
  - IRSA cho service accounts
  - Encryption at rest cho EBS volumes
  - Private subnets cho worker nodes

### Cost Optimization Tips

1. **S·ª≠ d·ª•ng Spot Instances**: C√≥ th·ªÉ c·∫•u h√¨nh node groups v·ªõi `capacity_type = "SPOT"` trong terraform.tfvars
2. **Single NAT Gateway**: Set `single_nat_gateway = true` trong terraform.tfvars ƒë·ªÉ gi·∫£m costs
3. **VPC Endpoints**: ƒê√£ ƒë∆∞·ª£c enable ƒë·ªÉ gi·∫£m NAT gateway costs
4. **Cluster Autoscaling**: T·ª± ƒë·ªông scale down khi kh√¥ng s·ª≠ d·ª•ng
5. **Right-sizing**: ƒêi·ªÅu ch·ªânh node instance types v√† counts ph√π h·ª£p v·ªõi workload

### 1. Deploy Infrastructure Components (Minikube/Local)

```bash
# Deploy Kafka (Strimzi Operator)
cd Kafka/strimzi-kafka-operator
kubectl apply -f install/cluster-operator/

# ƒê·ª£i operator ready
kubectl wait --for=condition=ready pod -l name=strimzi-cluster-operator -n strimzi-system --timeout=300s

# Deploy Kafka cluster
kubectl apply -f kafka-helm.yaml

# Deploy MongoDB
cd mongodb
helm install mongodb . -n crypto-infra --create-namespace

# Deploy Redis
cd redis
helm install redis . -n crypto-infra

# Deploy Prometheus & Grafana
cd deploy/helm
./deploy-monitoring.sh
```

### 2. Deploy Application Components

```bash
# T·∫°o namespace
cd deploy/k8s_web
kubectl apply -f namespace.yaml

# Deploy ConfigMap v√† Secrets
kubectl apply -f configmap.yaml
kubectl apply -f secret.yaml

# Deploy Backend API
kubectl apply -f backend-deployment.yaml
kubectl apply -f backend-service.yaml

# Deploy Frontend
kubectl apply -f frontend-deployment.yaml
kubectl apply -f frontend-service.yaml

# Deploy Ingress
kubectl apply -f ingress.yaml
```

### 3. Start Data Producers

```bash
# Start Kafka producers (c√≥ th·ªÉ ch·∫°y trong pods ho·∫∑c local)
cd Kafka

# Producer cho kline data
python binance_producer.py &

# Producer cho orderbook v√† trades
python binance_orderbook_trades_producer.py &

# Consumer t·ª´ Kafka v√†o Redis
python redis_consumer.py &
```

### 4. Start Airflow DAGs

Truy c·∫≠p Airflow UI (th∆∞·ªùng t·∫°i `http://localhost:8080`) v√† enable c√°c DAGs:
- `ohlc_5m_spark_aggregator` - Ch·∫°y m·ªói 5 ph√∫t
- `ohlc_1h_spark_aggregator` - Ch·∫°y m·ªói gi·ªù
- `ohlc_4h_spark_aggregator` - Ch·∫°y m·ªói 4 gi·ªù
- `ohlc_1d_spark_aggregator` - Ch·∫°y m·ªói ng√†y
- `ml_prediction_dag` - Training model ƒë·ªãnh k·ª≥

## üîß C·∫•u H√¨nh

### Environment Variables

**Backend (FastAPI)**:
```bash
MONGO_URI=mongodb://mongodb:27017
MONGO_DB=CRYPTO
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=
KAFKA_BOOTSTRAP=my-cluster-kafka-bootstrap:9092
KAFKA_TOPIC=crypto_kline_1m
CORS_ORIGINS=["http://localhost:3000"]
```

**Kafka Producers**:
```bash
KAFKA_BROKER=my-cluster-kafka-bootstrap.crypto-infra:9092
KAFKA_TOPIC=crypto_kline_1m
```

**Frontend**:
```bash
NEXT_PUBLIC_API_URL=http://backend-service:8000
NEXT_PUBLIC_WS_URL=ws://backend-service:8000
```

### MongoDB Collections

- `5m_kline`: OHLC data 5 ph√∫t
- `1h_kline`: OHLC data 1 gi·ªù
- `4h_kline`: OHLC data 4 gi·ªù
- `1d_kline`: OHLC data 1 ng√†y
- `predictions`: ML prediction results v·ªõi metadata

### Redis Keys Structure

- `crypto:{symbol}:1m:latest`: Latest kline data
- `crypto:{symbol}:1m:{timestamp}`: Historical kline data (sorted set index)
- `crypto:{symbol}:1m:index`: Sorted set ch·ª©a timestamps
- `orderbook:{symbol}:latest`: Orderbook snapshot v·ªõi bids/asks
- `trades:{symbol}:list`: Market trades list (sorted set)
- `ranking:top_gainers`: Coin ranking data (JSON array)
- `crypto:prediction:{symbol}`: ML predictions v·ªõi confidence scores

## üìä API Endpoints

### REST API

#### Historical Data
- `GET /ohlc?symbol=BTCUSDT&interval=5m&limit=200`: L·∫•y d·ªØ li·ªáu OHLC historical t·ª´ MongoDB
- `GET /ohlc?collection=5m_kline&symbol=BTCUSDT&limit=200`: L·∫•y t·ª´ collection c·ª• th·ªÉ

#### Real-time Data
- `GET /ohlc/realtime?symbol=BTCUSDT&limit=200`: L·∫•y d·ªØ li·ªáu OHLC real-time t·ª´ Redis
- `GET /latest?symbol=BTCUSDT`: L·∫•y latest kline data
- `GET /orderbook?symbol=BTCUSDT&limit=20`: L·∫•y orderbook snapshot
- `GET /trades?symbol=BTCUSDT&limit=50`: L·∫•y market trades

#### Ranking & Predictions
- `GET /ranking/top-gainers?limit=100&type=gainers`: L·∫•y coin ranking (gainers)
- `GET /ranking/top-gainers?limit=100&type=losers`: L·∫•y coin ranking (losers)
- `GET /prediction/BTCUSDT`: L·∫•y ML prediction cho symbol

### WebSocket Endpoints

- `WS /ws/kline?symbol=BTCUSDT&limit=100`: Real-time kline stream
  - Message types: `initial`, `latest`, `update`
- `WS /ws/orderbook?symbol=BTCUSDT`: Real-time orderbook stream
  - Message types: `initial`, `update`
- `WS /ws/trades?symbol=BTCUSDT&limit=50`: Real-time trades stream
  - Message types: `initial`, `update`

## üß™ Testing

### Test Backend API

```bash
cd backend_fastapi
python test_api.py

# Ho·∫∑c test v·ªõi curl
curl http://localhost:8000/health
curl http://localhost:8000/ohlc?symbol=BTCUSDT&limit=10
```

### Test Kafka Producer

```bash
cd Kafka
python binance_producer.py

# Ki·ªÉm tra messages trong Kafka
kubectl exec -it my-cluster-kafka-0 -n crypto-infra -- kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic crypto_kline_1m \
  --from-beginning
```

### Test Spark Jobs Locally

```bash
cd Spark/batch
python ohlc_5m_aggregator.py

# Ho·∫∑c submit qua Spark on K8s
kubectl apply -f Spark/apps/batch/ohlc-5m-aggregator.yaml
```

## üìà Monitoring

### Prometheus Metrics

H·ªá th·ªëng expose c√°c metrics sau:
- **Kafka**: Producer/consumer lag, throughput, error rate
- **Spark**: Job execution time, task completion rate, resource usage
- **API**: Request latency, error rate, throughput
- **Redis**: Memory usage, hit/miss ratio, connection count
- **MongoDB**: Connection pool, query latency, operation count

### Grafana Dashboards

Truy c·∫≠p Grafana t·∫°i `http://localhost:3000` (default: admin/admin) ƒë·ªÉ xem:
- **System Overview**: CPU, memory, network usage
- **Application Performance**: API latency, error rates
- **Data Pipeline Health**: Kafka lag, Spark job status
- **Business Metrics**: Trading volume, prediction accuracy

### Health Checks

```bash
# Backend health
curl http://localhost:8000/health

# Check pods status
kubectl get pods -n crypto-infra

# Check services
kubectl get svc -n crypto-infra
```

## üîç Troubleshooting

### Kafka kh√¥ng nh·∫≠n ƒë∆∞·ª£c d·ªØ li·ªáu
1. Ki·ªÉm tra Kafka broker connectivity: `kubectl get pods -n crypto-infra | grep kafka`
2. Verify WebSocket connection to Binance: Check producer logs
3. Check topic exists: `kubectl exec -it kafka-pod -- kafka-topics.sh --list`
4. Review producer logs: `kubectl logs -f <producer-pod>`

### Spark jobs fail
1. Ki·ªÉm tra Spark operator logs: `kubectl logs -f spark-operator`
2. Verify MongoDB connection t·ª´ Spark driver pod
3. Check resource limits: `kubectl describe sparkapplication <app-name>`
4. Review Spark driver logs: `kubectl logs <driver-pod>`

### Frontend kh√¥ng hi·ªÉn th·ªã data
1. Ki·ªÉm tra WebSocket connection: Open browser DevTools ‚Üí Network ‚Üí WS
2. Verify Redis c√≥ d·ªØ li·ªáu: `kubectl exec -it redis-pod -- redis-cli KEYS "*"`
3. Check backend API health: `curl http://backend-service:8000/health`
4. Review browser console errors

### MongoDB connection issues
1. Verify MongoDB pod running: `kubectl get pods -n crypto-infra | grep mongodb`
2. Check connection string trong ConfigMap
3. Test connection: `kubectl exec -it mongodb-pod -- mongosh`

## üìù License

MIT License

## üë• Contributors

- **V∆∞∆°ng VƒÉn Th√†nh** (20225094)
- **Ph·∫°m Huy S∆°n** (20225080)
- **Tr·∫ßn Tu·∫•n H√πng** (20225000)
- **V≈© Anh Huy** (20220029)
- **Tr·∫ßn Tu·∫•n H·∫£i** (20224976)

## üôè Acknowledgments

- **Binance API** for providing real-time cryptocurrency market data
- **Apache Foundation** for open-source Big Data tools (Kafka, Spark, Airflow)
- **TradingView** for charting library inspiration
- **Kubernetes Community** for excellent container orchestration platform

---

## ‚ö†Ô∏è L∆∞u √ù

**ƒê√¢y l√† d·ª± √°n h·ªçc t·∫≠p v√† nghi√™n c·ª©u**. H·ªá th·ªëng ƒë∆∞·ª£c x√¢y d·ª±ng cho m·ª•c ƒë√≠ch gi√°o d·ª•c v√† kh√¥ng n√™n ƒë∆∞·ª£c s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch trading th·ª±c t·∫ø m√† kh√¥ng c√≥ proper risk management v√† testing k·ªπ l∆∞·ª°ng.

**Disclaimer**: D·ª± ƒëo√°n gi√° t·ª´ ML model ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o v√† kh√¥ng ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c. Lu√¥n th·ª±c hi·ªán nghi√™n c·ª©u ri√™ng (DYOR) tr∆∞·ªõc khi ƒë∆∞a ra quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞.

---

[**‚¨ÜÔ∏è Back to top**](#h·ªá-th·ªëng-x·ª≠-l√Ω-d·ªØ-li·ªáu-cryptocurrency---real-time-trading-platform)
