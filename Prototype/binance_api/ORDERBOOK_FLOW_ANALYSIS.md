# Ph√¢n T√≠ch Lu·ªìng Order Book - Prototype/binance_api

## üìä T·ªïng Quan Lu·ªìng D·ªØ Li·ªáu

```
Binance WebSocket ‚Üí Producer (Kafka) ‚Üí Consumer (Kafka) ‚Üí Redis ‚Üí Frontend/Backend
```

---

## üîÑ C√°c Component Trong Lu·ªìng

### 1. **ob_stream_producer.py** - WebSocket Producer
**Vai tr√≤**: Nh·∫≠n d·ªØ li·ªáu real-time t·ª´ Binance v√† g·ª≠i v√†o Kafka

**Lu·ªìng ho·∫°t ƒë·ªông**:
1. K·∫øt n·ªëi WebSocket ƒë·∫øn Binance Futures API
   - URL: `wss://fstream.binance.com/stream?streams={symbols}@depth`
   - Symbols: BTCUSDT, ETHUSDT, BNBUSDT, SOLUSDT, ADAUSDT, XRPUSDT
   
2. Nh·∫≠n message t·ª´ WebSocket (ƒë·ªãnh d·∫°ng Binance depth stream)
   ```json
   {
     "data": {
       "s": "BTCUSDT",      // symbol
       "u": 123456789,      // update ID
       "b": [[price, qty]], // bids
       "a": [[price, qty]]  // asks
     }
   }
   ```

3. G·ª≠i v√†o Kafka topic `orderbook_update`
   - Key: symbol (ƒë·ªÉ partition theo symbol)
   - Value: payload t·ª´ Binance
   - Compression: LZ4
   - Linger: 10ms (batch messages)

**C·∫•u h√¨nh Kafka Producer**:
- Bootstrap servers: `localhost:9092`
- Serializer: JSON
- Compression: LZ4 (gi·∫£m bandwidth)
- Linger: 10ms (t·ªëi ∆∞u throughput)

---

### 2. **ob_handler.py** - Order Book Handler & Consumer
**Vai tr√≤**: X·ª≠ l√Ω order book updates t·ª´ Kafka, maintain local order book, l∆∞u v√†o Redis

#### 2.1. LocalOrderBook Class
**Ch·ª©c nƒÉng**: Qu·∫£n l√Ω order book local cho m·ªói symbol

**C·∫•u tr√∫c d·ªØ li·ªáu**:
- `bids`: SortedDict (s·∫Øp x·∫øp gi·∫£m d·∫ßn theo price)
- `asks`: SortedDict (s·∫Øp x·∫øp tƒÉng d·∫ßn theo price)
- `last_update_id`: ID update cu·ªëi c√πng t·ª´ Binance
- `is_synced`: Tr·∫°ng th√°i ƒë√£ sync snapshot ch∆∞a

**C√°c ph∆∞∆°ng th·ª©c**:
- `apply_update(data)`: √Åp d·ª•ng update v√†o order book
- `update_levels(levels, book_side)`: C·∫≠p nh·∫≠t bids/asks
  - N·∫øu qty = 0 ‚Üí x√≥a level ƒë√≥
  - N·∫øu qty > 0 ‚Üí th√™m/c·∫≠p nh·∫≠t level
- `get_payload()`: L·∫•y top 10 bids/asks ƒë·ªÉ l∆∞u Redis
- `display_top()`: Hi·ªÉn th·ªã top 3 bids/asks

#### 2.2. Kafka Consumer
**Lu·ªìng x·ª≠ l√Ω**:

1. **K·∫øt n·ªëi Kafka**
   - Topic: `orderbook_update`
   - Group ID: `ob_consumers`
   - Auto offset reset: `latest`
   - Deserializer: JSON

2. **X·ª≠ l√Ω message t·ª´ Kafka**:
   ```
   Nh·∫≠n message ‚Üí Ki·ªÉm tra symbol ‚Üí T·∫°o LocalOrderBook n·∫øu ch∆∞a c√≥
   ‚Üí Fetch snapshot t·ª´ Binance REST API (n·∫øu ch∆∞a sync)
   ‚Üí Buffer events trong khi ch·ªù snapshot
   ‚Üí √Åp d·ª•ng updates v√†o order book
   ‚Üí L∆∞u v√†o Redis m·ªói 100ms (rate limiting)
   ```

3. **Snapshot Sync Process**:
   - Khi nh·∫≠n symbol m·ªõi ‚Üí t·∫°o LocalOrderBook
   - Fetch snapshot t·ª´: `https://fapi.binance.com/fapi/v1/depth?symbol={symbol}&limit=1000`
   - Buffer c√°c events nh·∫≠n ƒë∆∞·ª£c trong khi ch·ªù snapshot
   - Sau khi c√≥ snapshot:
     - √Åp d·ª•ng snapshot v√†o order book
     - √Åp d·ª•ng c√°c events ƒë√£ buffer (n·∫øu update_id > snapshot_id)
     - ƒê√°nh d·∫•u `is_synced = True`

4. **L∆∞u v√†o Redis**:
   - Key: `LIVE_ORDERBOOK` (Hash)
   - Field: `{symbol}` (v√≠ d·ª•: BTCUSDT)
   - Value: JSON payload v·ªõi top 10 bids/asks
   - Rate limiting: Ch·ªâ l∆∞u m·ªói 100ms (0.1s) ƒë·ªÉ tr√°nh spam Redis

**C·∫•u tr√∫c d·ªØ li·ªáu Redis**:
```json
{
  "s": "BTCUSDT",
  "b": [[price, qty], ...],  // Top 10 bids
  "a": [[price, qty], ...],  // Top 10 asks
  "u": 123456789             // Last update ID
}
```

---

### 3. **redis_read_test.py** - Test Consumer
**Vai tr√≤**: Test ƒë·ªçc order book t·ª´ Redis

**Ho·∫°t ƒë·ªông**:
- ƒê·ªçc t·ª´ Redis key `LIVE_ORDERBOOK` field `ETHUSDT`
- In ra console m·ªói 1 gi√¢y
- Ki·ªÉm tra d·ªØ li·ªáu c√≥ t·ªìn t·∫°i kh√¥ng

---

## üîÄ Lu·ªìng D·ªØ Li·ªáu Chi Ti·∫øt

### Phase 1: Initialization
```
1. Producer k·∫øt n·ªëi Binance WebSocket
2. Producer nh·∫≠n depth stream updates
3. Producer g·ª≠i v√†o Kafka topic "orderbook_update"
```

### Phase 2: Consumer Processing
```
1. Consumer nh·∫≠n message t·ª´ Kafka
2. Ki·ªÉm tra symbol c√≥ trong orderbooks dict ch∆∞a
3. N·∫øu ch∆∞a c√≥:
   - T·∫°o LocalOrderBook m·ªõi
   - T·∫°o event buffer
   - Fetch snapshot t·ª´ Binance REST API (async)
   - Buffer events trong khi ch·ªù snapshot
4. N·∫øu ƒë√£ c√≥:
   - Ki·ªÉm tra is_synced
   - N·∫øu ch∆∞a sync: buffer event
   - N·∫øu ƒë√£ sync: apply update ngay
```

### Phase 3: Snapshot Sync
```
1. Fetch snapshot t·ª´ Binance REST API
2. Parse snapshot (bids, asks, lastUpdateId)
3. Update LocalOrderBook v·ªõi snapshot data
4. Apply buffered events (n·∫øu update_id > snapshot_id)
5. Set is_synced = True
```

### Phase 4: Real-time Updates
```
1. Nh·∫≠n update t·ª´ Kafka
2. Ki·ªÉm tra update_id > last_update_id
3. Apply update v√†o LocalOrderBook
4. Rate limit: Ch·ªâ l∆∞u Redis m·ªói 100ms
5. L∆∞u top 10 bids/asks v√†o Redis
```

---

## üéØ ƒê·∫∑c ƒêi·ªÉm K·ªπ Thu·∫≠t

### 1. **Snapshot Sync Pattern**
- **V·∫•n ƒë·ªÅ**: WebSocket stream ch·ªâ g·ª≠i updates, kh√¥ng c√≥ full order book
- **Gi·∫£i ph√°p**: Fetch snapshot t·ª´ REST API khi b·∫Øt ƒë·∫ßu
- **Buffer events**: L∆∞u events nh·∫≠n ƒë∆∞·ª£c trong khi ch·ªù snapshot
- **Apply buffered**: √Åp d·ª•ng events sau snapshot ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n

### 2. **Rate Limiting**
- **L√Ω do**: Tr√°nh spam Redis v·ªõi qu√° nhi·ªÅu writes
- **C∆° ch·∫ø**: Ch·ªâ l∆∞u Redis m·ªói 100ms (10 writes/gi√¢y)
- **Trade-off**: Gi·∫£m latency nh∆∞ng ƒë·∫£m b·∫£o performance

### 3. **SortedDict cho Order Book**
- **Bids**: S·∫Øp x·∫øp gi·∫£m d·∫ßn (gi√° cao nh·∫•t tr∆∞·ªõc)
- **Asks**: S·∫Øp x·∫øp tƒÉng d·∫ßn (gi√° th·∫•p nh·∫•t tr∆∞·ªõc)
- **L·ª£i √≠ch**: O(log n) cho insert/delete, O(1) cho top levels

### 4. **Update ID Validation**
- Ki·ªÉm tra `update_id > last_update_id` tr∆∞·ªõc khi apply
- ƒê·∫£m b·∫£o kh√¥ng apply updates c≈© (out-of-order)

### 5. **Error Handling**
- Retry k·∫øt n·ªëi Kafka n·∫øu fail
- Exception handling cho snapshot fetch
- Graceful shutdown v·ªõi producer.flush()

---

## üìà Performance Considerations

### Throughput
- **WebSocket**: Real-time updates t·ª´ Binance (milliseconds)
- **Kafka**: Batch v·ªõi linger 10ms, compression LZ4
- **Redis**: Rate limited 10 writes/second per symbol

### Latency
- **End-to-end**: ~100-200ms (WebSocket ‚Üí Kafka ‚Üí Consumer ‚Üí Redis)
- **Snapshot sync**: ~500ms-1s (REST API call)

### Memory
- **LocalOrderBook**: L∆∞u full order book (1000 levels) trong memory
- **Event buffers**: T·∫°m th·ªùi l∆∞u events trong khi ch·ªù snapshot

---

## üîß C·∫•u H√¨nh

### Kafka
- Topic: `orderbook_update`
- Partitions: Theo symbol (key-based partitioning)
- Compression: LZ4
- Producer linger: 10ms

### Redis
- Key: `LIVE_ORDERBOOK` (Hash)
- Field: `{SYMBOL}` (uppercase)
- Value: JSON v·ªõi top 10 bids/asks
- TTL: Kh√¥ng c√≥ (persistent)

### Binance API
- WebSocket: `wss://fstream.binance.com/stream`
- REST API: `https://fapi.binance.com/fapi/v1/depth`
- Symbols: BTCUSDT, ETHUSDT, BNBUSDT, SOLUSDT, ADAUSDT, XRPUSDT

---

## üöÄ C√°ch Ch·∫°y

### 1. Start Producer
```bash
python ob_stream_producer.py
```

### 2. Start Consumer/Handler
```bash
python ob_handler.py
```

### 3. Test Read from Redis
```bash
python redis_read_test.py
```

---

## üîÑ So S√°nh V·ªõi Production Code

### Prototype (binance_api)
- LocalOrderBook trong memory
- L∆∞u v√†o Redis hash `LIVE_ORDERBOOK`
- Top 10 bids/asks
- Rate limit 100ms

### Production (Kafka/)
- L∆∞u full order book v√†o Redis
- Key: `orderbook:{symbol}:latest`
- Full order book (kh√¥ng gi·ªõi h·∫°n)
- Real-time updates qua Kafka consumer

---

## ‚ö†Ô∏è L∆∞u √ù

1. **Snapshot Sync**: C·∫ßn ƒë·∫£m b·∫£o snapshot ƒë∆∞·ª£c fetch tr∆∞·ªõc khi apply updates
2. **Update ID**: Ph·∫£i validate ƒë·ªÉ tr√°nh out-of-order updates
3. **Rate Limiting**: C√¢n b·∫±ng gi·ªØa latency v√† Redis performance
4. **Error Recovery**: C·∫ßn retry mechanism cho snapshot fetch
5. **Memory**: LocalOrderBook l∆∞u full book, c·∫ßn monitor memory usage

---

## üìù T√≥m T·∫Øt

Lu·ªìng order book prototype n√†y minh h·ªça:
- ‚úÖ WebSocket streaming t·ª´ Binance
- ‚úÖ Kafka l√†m message queue
- ‚úÖ Snapshot sync pattern
- ‚úÖ Local order book management
- ‚úÖ Redis storage v·ªõi rate limiting
- ‚úÖ Event buffering trong khi sync

ƒê√¢y l√† foundation t·ªët cho production system, nh∆∞ng c·∫ßn th√™m:
- Error recovery mechanisms
- Monitoring & logging
- Horizontal scaling
- Data persistence strategies

